{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation and automatic differentiation:\n",
    "\n",
    "[My purpose: To dump all that I learnt. To make/express it the best way I can]\n",
    "Few months ago I was trying to understand how learning actually happens and it struck me that I understood backpropagation in a very shallow way. So, I decided to understand it in depth and see how it is actually implemented in big neural networks. It will be a long post. Its not intended as quick read to understand backprop. We will be looking into it in depth and I hope you find the article useful. \n",
    "\n",
    "### Intro to backprop:\n",
    "Central to the concept of backprop is the idea of a cost function. Cost functions let us choose what we want to achieve. Either we want to maximize all the rewards or we want to minimize our errors and want our approximations to be spot on. Cost function helps to formalize the uncertainty of our models[check Appendix A] and reduce it.\n",
    "\n",
    "Let's say our model consists of parameters $\\theta$ and our cost function is $\\mathcal{J}(\\theta)$. So, if we have the gradients $\\frac{\\partial \\mathcal{J}(\\theta)}{\\partial \\theta}$ then we can update the parameters $\\theta$ using gradient descent[For more on gradients and gradient descent check Appendix B].\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    start with the idea of cost function\n",
    "    List of good references to understand basics of bakprop\n",
    "    chain rule primer\n",
    "Modular structure of backprop:\n",
    "    the three functions\n",
    "Calculating gradients using jacobian products:\n",
    "    introduce vjp function\n",
    "Calculating gradients using automatic differentitation\n",
    "    how it converts into sequntial \n",
    "    autodiff lib\n",
    "Compuational graphs\n",
    "    static vs dynamic\n",
    "    \n",
    "References:\n",
    "\n",
    "Appendix:\n",
    "\n",
    "### Appendix A: Cost Functions\n",
    "To understand the need for a cost function we need to understand what learning is. In context of machine learning and deep learning algorithms, learning means ability to predict. In our models we want to reduce the uncertainity involved in our predictions or our learning of the data. We want our predictions to be spot on. We measure uncertainty using entropy.\n",
    "\n",
    "The measure of uncertainty is called entropy. By definition\n",
    "\n",
    "\\begin{equation*} \\mathcal{E} = - \\sum \\mathcal{P}(x) ln \\mathcal{P}(x) \\end{equation*}\n",
    "\n",
    "Lets see how cost functions reduce entropy of predictions for different tasks.\n",
    "\n",
    "#### For classification tasks:\n",
    "Lets task a classification task of n classes using softmax. \n",
    "So, the probability that a particular sample $x$ is of class n is:\n",
    "\n",
    "\\begin{equation*} \\mathcal{P}(x = n) = [\\frac{e^{k_n}}{\\sum_{i}^{n} e^{k_j}}]^{\\Omega_n} \\end{equation*}\n",
    "where, $\\Omega_n = \\begin{cases}\n",
    "1 &\\text{if } \\bar{y} \\text{=1 i.e. label for the class n is 1 ,else} \\\\\n",
    "0\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "So, our likelihood for one data sample is:\n",
    "\\begin{equation*} \\mathcal{P}(x) = \\prod_{i=0}^{n}[\\frac{e^{k_n}}{\\sum_{j}^{n} e^{k_j}}]^{\\Omega_i} \\end{equation*}\n",
    " \n",
    "So entropy of classification for one data sample becomes:\n",
    "\n",
    "\\begin{equation*} \\mathcal{E} = - \\sum_{i=0}^{n} [\\frac{e^{k_n}}{\\sum_{j}^{n} e^{k_j}}]^{\\Omega_i} {\\Omega_i} \\ln [\\frac{e^{k_n}}{\\sum_{j}^{n} e^{k_j}}] \\end{equation*}\n",
    "\n",
    "The above expression may seem daunting but if you notice $\\Omega_i$ is 0 for all non label classes and when $\\Omega_i$ is 1 then the above expression gets it lowest value(0) when the model gives the probablility of 1 to the label class which will be a spot on prediction for the label class.\n",
    "\n",
    "#### For regression tasks:\n",
    "The first go to option for regression tasks is MeanSquarredError. But in MSE there is no notion of a $\\mathcal{P}(y)$. So we assume that by predicting $y$ we are learning a distribution of the logits. A go-to choice is to learn a normal distribution of our logits. We assume that are logits are the mean of that distribution and we find the $\\mathcal{P}(\\bar{y})$ using the probability density function(PDF) of the distribution. The idea is then to maximize the probabilities $\\mathcal{P}(\\bar{y})$ which happens when $\\bar{y} = y$.\n",
    "\n",
    "Using PDF of a normal distribution,\n",
    "\\begin{equation*} \\mathcal{P}(x) = \\frac{e^{-(\\bar{y} - y)^{2}/(2\\sigma^{2}) }} {\\sigma\\sqrt{2\\pi}}\\end{equation*}\n",
    "\n",
    "So our entropy becomes,\n",
    "\\begin{align*} \\mathcal{E} &= - \\frac{e^{-^{2}/(2\\sigma^{2}) }} {\\sigma\\sqrt{2\\pi}}(-(\\bar{y} - y)^{2}/(2\\sigma^{2})- \\ln(\\sigma\\sqrt{2\\pi})) \\\\\n",
    "&\\propto  \\frac{e^{-^{2}/(2\\sigma^{2}) }} {\\sigma\\sqrt{2\\pi}}((\\bar{y} - y)^{2})\n",
    "\\end{align*}\n",
    "\n",
    "Again, a daunting expression but it minimizes when $(\\bar{y} = y)$\n",
    "\n",
    "So, as we saw in both cases, the point of a cost function is to measure the uncertainty of the model and reduce it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
